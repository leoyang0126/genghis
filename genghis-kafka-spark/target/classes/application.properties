server.port=8999
#============== kafka ===================
kafka.consumer.zookeeper.connect=101.132.254.51:2181
kafka.consumer.servers=101.132.254.51:9092
kafka.consumer.enable.auto.commit=true
kafka.consumer.session.timeout=6000
kafka.consumer.auto.commit.interval=100
kafka.consumer.auto.offset.reset=latest
kafka.consumer.topic=test
kafka.consumer.group.id=test
kafka.consumer.concurrency=10

kafka.producer.servers=101.132.254.51:9092
kafka.producer.retries=0
kafka.producer.batch.size=4096
kafka.producer.linger=1
kafka.producer.buffer.memory=40960

#------------spark----------
spring.application.name=genghis-kafka-spark
# LOGGING
logging.level.root=info
logging.path=/opt/${spring.application.name}
#spark config start
spark.driver.memory=32g
spark.worker.memory=25g
spark.executor.memory=25g
spark.rpc.message.maxSize=1024
#spark master
#spark.master = spark://10.222.17.21:7077
spark.master = local
#spark topics ','号分割
spark.kafka.topics = test
#kafka集群地址，'，'号分割
kafka.broker.list = 101.132.254.51:9092
#从kafka拉数据的间隔时间，单位 S
spark.stream.kafka.durations=10
#spark config end
